From 4090fff9ddac006943dd0846c9d93cc0b02c1260 Mon Sep 17 00:00:00 2001
From: Lin Xie <lin.xie@intel.com>
Date: Mon, 6 May 2019 11:24:53 +0800
Subject: [PATCH] Fix code style and symbols visibility for 2019R1

* append minor change for dldt 2019r1.1
---
 inference-engine/include/ie_api_wrapper.h        | 24 +++++++-------------
 inference-engine/include/ie_common_wrapper.h     | 29 +++++++++---------------
 inference-engine/src/ie_c_wrapper/CMakeLists.txt |  6 +++--
 inference-engine/src/ie_c_wrapper/ie_context.cpp | 27 +---------------------
 inference-engine/src/ie_c_wrapper/ie_context.h   |  5 ----
 5 files changed, 24 insertions(+), 67 deletions(-)

diff --git a/inference-engine/include/ie_api_wrapper.h b/inference-engine/include/ie_api_wrapper.h
index 5284b5f..9c178f5 100644
--- a/inference-engine/include/ie_api_wrapper.h
+++ b/inference-engine/include/ie_api_wrapper.h
@@ -1,17 +1,9 @@
- // Licensed under the Apache License, Version 2.0 (the "License");
- // you may not use this file except in compliance with the License.
- // You may obtain a copy of the License at
- //
- //      http://www.apache.org/licenses/LICENSE-2.0
- //
- // Unless required by applicable law or agreed to in writing, software
- // distributed under the License is distributed on an "AS IS" BASIS,
- // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- // See the License for the specific language governing permissions and
- // limitations under the License.
-
-#ifndef _IE_PLUGIN_WRAPPER_H_
-#define _IE_PLUGIN_WRAPPER_H_
+// Copyright (C) 2018-2019 Intel Corporation
+// SPDX-License-Identifier: Apache-2.0
+//
+
+#ifndef OPENVINO_DLDT_INFERENCE_ENGINE_INCLUDE_IE_API_WRAPPER_H_
+#define OPENVINO_DLDT_INFERENCE_ENGINE_INCLUDE_IE_API_WRAPPER_H_
 
 #include "ie_common_wrapper.h"
 
@@ -109,7 +101,7 @@ void IESetInput(void * contextPtr, unsigned int idx, IEData * data);
 * input: the pointer o inference engine context
 * input: the output buffer
 */
-//void IESetOutput(void * contextPtr, IEData * data);
+// void IESetOutput(void * contextPtr, IEData * data);
 
 /*
 * the API to get the result pointer after the execution
@@ -136,4 +128,4 @@ void IESetCpuThreadsNum(void *contextPtr, unsigned int num);
 #ifdef __cplusplus
 }
 #endif
-#endif
+#endif  // OPENVINO_DLDT_INFERENCE_ENGINE_INCLUDE_IE_API_WRAPPER_H_
diff --git a/inference-engine/include/ie_common_wrapper.h b/inference-engine/include/ie_common_wrapper.h
index 59ba209..e82b65f 100644
--- a/inference-engine/include/ie_common_wrapper.h
+++ b/inference-engine/include/ie_common_wrapper.h
@@ -1,16 +1,9 @@
- // Licensed under the Apache License, Version 2.0 (the "License");
- // you may not use this file except in compliance with the License.
- // You may obtain a copy of the License at
- //
- //      http://www.apache.org/licenses/LICENSE-2.0
- //
- // Unless required by applicable law or agreed to in writing, software
- // distributed under the License is distributed on an "AS IS" BASIS,
- // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- // See the License for the specific language governing permissions and
- // limitations under the License.
-#ifndef _IE_COMMON_WRAPPER_H_
-#define _IE_COMMON_WRAPPER_H_
+// Copyright (C) 2018-2019 Intel Corporation
+// SPDX-License-Identifier: Apache-2.0
+//
+
+#ifndef OPENVINO_DLDT_INFERENCE_ENGINE_INCLUDE_IE_COMMON_WRAPPER_H_
+#define OPENVINO_DLDT_INFERENCE_ENGINE_INCLUDE_IE_COMMON_WRAPPER_H_
 
 #include <stddef.h>
 
@@ -57,7 +50,7 @@ typedef enum tagIEPrecisinType {
 * @brief Layouts that the inference engine supports
 */
 typedef enum tagIELayoutType {
-    IE_ANY = 0,// "any" layout
+    IE_ANY = 0,  // "any" layout
     // I/O data layouts
     IE_NCHW = 1,
     IE_NHWC = 2,
@@ -167,12 +160,12 @@ typedef struct tagIEData {
 #define NUM_DATA_POINTS 4
     unsigned char *data[NUM_DATA_POINTS];  // pointers to picture planes
     int        linesize[NUM_DATA_POINTS];  // size in bytes of each picture line
-    unsigned int size;  //byte size
+    unsigned int size;  // byte size
     unsigned int width;
     unsigned int height;
     unsigned int channelNum;
     unsigned int batchIdx;
-    IEPrecisionType precision; //IE_FP32:IE_FP16:IE_U8
+    IEPrecisionType precision;  // IE_FP32:IE_FP16:IE_U8
     IEMemoryType memType;
     IEImageFormatType imageFormat;
     IEDataType dataType;
@@ -190,7 +183,7 @@ typedef struct tagIEConfig {
     char * pluginPath;
     char * cpuExtPath;
     char * cldnnExtPath;
-    char * modelFileName; // Bin file name
+    char * modelFileName;  // Bin file name
     char * outputLayerName;
     unsigned int  perfCounter;
     unsigned int inferReqNum;   // it work with async mode and value is 1 in default.
@@ -199,4 +192,4 @@ typedef struct tagIEConfig {
 #ifdef __cplusplus
 }
 #endif
-#endif
+#endif  // OPENVINO_DLDT_INFERENCE_ENGINE_INCLUDE_IE_COMMON_WRAPPER_H_
diff --git a/inference-engine/src/ie_c_wrapper/CMakeLists.txt b/inference-engine/src/ie_c_wrapper/CMakeLists.txt
index 063f923..8e91e70 100644
--- a/inference-engine/src/ie_c_wrapper/CMakeLists.txt
+++ b/inference-engine/src/ie_c_wrapper/CMakeLists.txt
@@ -20,8 +20,10 @@ include_directories(
     ${CMAKE_CURRENT_SOURCE_DIR}
 )
 
-if(WIN32)
-    add_definitions(-DIMPLEMENT_INFERENCE_ENGINE_API)
+add_definitions(-DIMPLEMENT_INFERENCE_ENGINE_API)
+
+if (UNIX OR APPLE AND ${CMAKE_BUILD_TYPE} STREQUAL "Release")
+    add_definitions(-fvisibility=default)
 endif()
 
 add_library(${TARGET_NAME} SHARED ${SOURCES} ${HEADERS})
diff --git a/inference-engine/src/ie_c_wrapper/ie_context.cpp b/inference-engine/src/ie_c_wrapper/ie_context.cpp
index 0dca077..ba75cba 100644
--- a/inference-engine/src/ie_c_wrapper/ie_context.cpp
+++ b/inference-engine/src/ie_c_wrapper/ie_context.cpp
@@ -53,7 +53,7 @@ void CIEContext::loadModel(IEConfig * config)
         path.assign(config->pluginPath);
 
     InferenceEngine::PluginDispatcher dispatcher({ path, "../../../lib/intel64", "" });
-    targetDevice = getDeviceFromId(config->targetId);
+    targetDevice = (InferenceEngine::TargetDevice)config->targetId;
     /** Loading plugin for device **/
     plugin = dispatcher.getPluginByDevice(getDeviceName(targetDevice));
     enginePtr = plugin;
@@ -431,31 +431,6 @@ InferenceEngine::TargetDevice CIEContext::getDeviceFromString(const std::string
     return InferenceEngine::TargetDeviceInfo::fromStr(deviceName);
 }
 
-InferenceEngine::TargetDevice CIEContext::getDeviceFromId(IETargetDeviceType device) {
-    switch (device) {
-    case IE_Default:
-        return InferenceEngine::TargetDevice::eDefault;
-    case IE_Balanced:
-        return InferenceEngine::TargetDevice::eBalanced;
-    case IE_CPU:
-        return InferenceEngine::TargetDevice::eCPU;
-    case IE_GPU:
-        return InferenceEngine::TargetDevice::eGPU;
-    case IE_FPGA:
-        return InferenceEngine::TargetDevice::eFPGA;
-    case IE_MYRIAD:
-        return InferenceEngine::TargetDevice::eMYRIAD;
-    case IE_HDDL:
-        return InferenceEngine::TargetDevice::eHDDL;
-    case IE_GNA:
-        return InferenceEngine::TargetDevice::eGNA;
-    case IE_HETERO:
-        return InferenceEngine::TargetDevice::eHETERO;
-    default:
-        return InferenceEngine::TargetDevice::eCPU;
-    }
-}
-
 InferenceEngine::Layout CIEContext::estimateLayout(const int chNum)
 {
     if (chNum == 4)
diff --git a/inference-engine/src/ie_c_wrapper/ie_context.h b/inference-engine/src/ie_c_wrapper/ie_context.h
index 45cdbb6..6f52ab5 100644
--- a/inference-engine/src/ie_c_wrapper/ie_context.h
+++ b/inference-engine/src/ie_c_wrapper/ie_context.h
@@ -178,11 +178,6 @@ protected:
     InferenceEngine::TargetDevice getDeviceFromString(const std::string &deviceName);
 
     /*
-    * @brief Converts enum value to TargetDevice
-    */
-    InferenceEngine::TargetDevice getDeviceFromId(IETargetDeviceType device);
-
-    /*
     * @brief estimate the data layout according to the channel number
     */
     InferenceEngine::Layout estimateLayout(const int chNum);
-- 
2.7.4

